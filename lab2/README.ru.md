[![en](https://img.shields.io/badge/lang-en-blue.svg)](README.md)
[![made-with-python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)](https://www.python.org/)
[![GitHub license](https://badgen.net/github/license/Naereen/Strapdown.js)](https://github.com/italian/simple_automatic_machine_learning_pipeline/blob/main/LICENSE)

# Простой автоматический конвейер машинного обучения на Jenkins

Это реализация простого конвейера для автоматизации работы с моделью машинного обучения на Jenkins. Конвейер состоит из нескольких ключевых этапов, описанных в файле [Jenkinsfile](./Jenkinsfile).

В этом конвейере используется набор данных `wine`, доступный через функцию `load_wine` из библиотеки `scikit-learn`. Это классический и очень простой набор данных для задач многоклассовой классификации. Набор данных содержит 13 различных параметров для вин с 178 образцами. Для работы с этим набором данных можно использовать различные подходы машинного обучения, включая классификацию, для предсказания класса вина на основе его характеристик.

## Этапы

### 1. Настройка Python окружения

На этом этапе создается виртуальное окружение Python, если оно еще не создано, активируется и устанавливаются зависимости из файла [requirements.txt](./requirements.txt).

### 2. Создание набора данных

Скрипт [create_dataset.py](./python_scripts/create_dataset.py) генерирует набор данных о винах, используя набор данных `load_wine` из библиотеки `sklearn.datasets`, и сохраняет его в формате `CSV` в папке `data`.

### 3. Предобработка данных

Скрипт [data_preprocessing.py](./python_scripts/data_preprocessing.py) выполняет предобработку данных, включая выбор пяти лучших признаков с помощью `SelectKBest` и метода `chi2`, а также стандартизацию данных с помощью `StandardScaler`. Данные разделяются на обучающую и тестовую выборки.

### 4. Обучение модели

Скрипт [train_model.py](./python_scripts/train_model.py) создает и обучает модель случайного леса на тренировочных данных. После обучения модель сохраняется в формате `.pkl` для дальнейшего использования.

### 5. Тестирование модели

Скрипт [test_model.py](./python_scripts/test_model.py) проверяет производительность обученной модели на тестовых данных. Для оценки производительности используются метрики `accuracy`, `precision`, `recall`, `F1-score`.

## Использование

Для запуска конвейера, клонируйте репозиторий и настройте Jenkins для выполнения `Jenkinsfile`:
1. **Создание нового Pipeline проекта**.
   - В Jenkins, выберите New Item в левом верхнем углу.
   - Введите имя вашего проекта, например, lab2.
   - Выберите Pipeline.
   - Нажмите OK.
2. **Настройка Pipeline**.
   - В разделе Pipeline, выберите Pipeline script from SCM.
   - В поле Repository URL введите путь к этому репозиторию (`https://github.com/italian/simple_automatic_machine_learning_pipeline`).
   - Убедитесь, что выбрана правильный ветвь main.
   - В поле Script Path укажите путь к Jenkinsfile - `lab2/Jenkinsfile`.
   - Нажмите Save.
3. **Запуск Pipeline**.
   - Запустите Pipeline, нажав на Build Now в левом боковом меню проекта в Jenkins.

## Требования

- Python 3.7+
- Библиотеки:
    - pandas==1.3.3
    - scikit-learn==1.4.1.post1

## Анализ качества модели

В результате обучения и тестирования модели с помощью этого конвейера, получили метрики показывающие точность, полноту, F1-оценку и точность равными 1.0 как на тренировочных, так и на тестовых данных. Это указывают на идеальную производительность модели. Однако, стоит быть осторожным с интерпретацией таких результатов, так как они могут указывать на несколько возможных ситуаций:

- **Переобучение (Overfitting)**. Модель может быть слишком сложной и "запомнить" тренировочные данные, включая шум и выбросы.
- **Простая задача или небольшой набор данных**. Если задача простая или набор данных небольшой, модель может легко достичь высокой точности без значительного риска переобучения.
- **Сбалансированность классов**. Если классы в данных сбалансированы, модель может показать высокую точность, даже если она не идеально хороша.
- **Ошибка в оценке**. Возможно, была допущена ошибка в процессе оценки модели, например, использование неправильных метрик или неправильное разделение данных.

## Рекомендации по улучшению

### **Использование других моделей машинного обучения**

Можно попробовать использовать другие модели, такие как градиентный бустинг (Gradient Boosting), SVM или нейронные сети. Это может помочь сравнить качество моделей и выбрать наиболее подходящую для конкретной задачи. Например, градиентный бустинг может показать лучшие результаты на некоторых задачах благодаря своей способности к обработке нелинейных зависимостей и устойчивости к выбросам. SVM может быть предпочтительнее для задач с высокой размерностью признаков, а нейронные сети могут быть эффективны для задач с большим количеством признаков и сложной структурой данных.

### **Применения кросс-валидации**

Хорошо бы применить кросс-валидацию, которая позволяет более надежно оценить качество модели, разделяя данные на несколько подмножеств и обучая модель на разных комбинациях этих подмножеств. Это помогает уменьшить влияние случайности разделения данных на оценку модели и дает более точное представление о ее производительности.

### **Улучшение этапа предобработки**

На этапе предобработки выделяем k=5 лучших признаков, используя SelectKBest и метод chi2. Этот подход может быть улучшен путем использования других методов выбора признаков, например, рекурсивное уменьшение (Recursive Feature Elimination, RFE), которые могут учитывать взаимосвязи между признаками и более точно определять важность признаков для задачи классификации.

### **Оптимизация параметра `n_estimators` в `RandomForestClassifier`**

Выбор оптимального значения `n_estimators` зависит от конкретной задачи и данных. Один из подходов — использовать кросс-валидацию для оценки производительности модели с различными значениями `n_estimators` и выбрать значение, при котором модель показывает наилучшие результаты. Другой подход — использовать методы, такие как `RandomizedSearchCV` из `scikit-learn`, для автоматического поиска оптимального значения параметра.

Важно отметить, что хотя увеличение `n_estimators` может улучшить производительность модели, есть предел, после которого дополнительные деревья не принесут значительного улучшения. Это связано с тем, что случайный лес стремится к стабилизации после достижения определенного количества деревьев, и добавление еще большего количества деревьев не приведет к дополнительному улучшению.

## Выводы

Рекомендуется провести дополнительный глубокий анализ качества модели, используя кросс-валидацию и сравнение производительности с другими моделями машинного обучения. Также стоит рассмотреть возможность улучшения этапа предобработки данных и оптимизации параметра `n_estimators` в `RandomForestClassifier` для улучшения производительности модели.

## Лицензия

Этот проект распространяется под лицензией MIT.